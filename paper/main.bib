@inproceedings{10.1145/3466752.3480098,
author = {Kang, Ki-Dong and Park, Gyeongseo and Kim, Hyosang and Alian, Mohammad and Kim, Nam Sung and Kim, Daehoon},
title = {NMAP: Power Management Based on Network Packet Processing Mode Transition for Latency-Critical Workloads},
year = {2021},
isbn = {9781450385572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3466752.3480098},
doi = {10.1145/3466752.3480098},
abstract = {Processor power management exploiting Dynamic Voltage and Frequency Scaling (DVFS) plays a crucial role in improving the data-center’s energy efficiency. However, we observe that current power management policies in Linux (i.e., governors) often considerably increase tail response time (i.e., violate a given Service Level Objective (SLO)) and energy consumption of latency-critical applications. Furthermore, the previously proposed SLO-aware power management policies oversimplify network request processing and ignore the fact that network requests arrive at the application layer in bursts. Considering the complex interplay between the OS and network devices, we propose a power management framework exploiting network packet processing mode transitions in the OS to quickly react to the processing demands from the received network requests. Our proposed power management framework tracks the transitions between polling and interrupt in the network software stack to detect excessive packet processing on the cores and immediately react to the load changes by updating the voltage and frequency (V/F) states. Our experimental results show that our framework does not violate SLO and reduces energy consumption by up to 35.7\% and 14.8\% compared to Linux governors and state-of-the-art SLO-aware power management techniques, respectively.},
booktitle = {MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {143–154},
numpages = {12},
keywords = {Tail latency, Dynamic voltage and frequency scaling, Power management, Data-center server},
location = {Virtual Event, Greece},
series = {MICRO '21}
}

@inproceedings{10.1145/3343737.3343740,
author = {Sharafzadeh, Erfan and Kohroudi, Seyed Alireza Sanaee and Asyabi, Esmail and Sharifi, Mohsen},
title = {Yawn: A CPU Idle-State Governor for Datacenter Applications},
year = {2019},
isbn = {9781450368933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3343737.3343740},
doi = {10.1145/3343737.3343740},
abstract = {Idle-state governors partially turn off idle CPUs, allowing them to go to states known as idle-states to save power. Exiting from these idle-sates, however, imposes delays on the execution of tasks and aggravates tail latency. Menu, the default idle-state governor of Linux, predicts periods of idleness based on the historical data and the disk I/O information to choose proper idle-sates. Our experiments show that Menu can save power, but at the cost of sacrificing tail latency, making Menu an inappropriate governor for data centers that host latency-sensitive applications. In this paper, we present the initial design of Yawn, an idle-state governor that aims to mitigate tail latency without sacrificing power. Yawn leverages online machine learning techniques to predict the idle periods based on information gathered from all parameters affecting idleness, including network I/O, resulting in more accurate predictions, which in turn leads to reduced response times. Preliminary benchmarking results demonstrate that Yawn reduces the 99th latency percentile of Memcached requests by up to 40\%.},
booktitle = {Proceedings of the 10th ACM SIGOPS Asia-Pacific Workshop on Systems},
pages = {91–98},
numpages = {8},
keywords = {Operating System, Tail Latency, Power Management, Idle-state Governor},
location = {Hangzhou, China},
series = {APSys '19}
}

@inproceedings{10.1145/3419111.3421298,
author = {Asyabi, Esmail and Bestavros, Azer and Sharafzadeh, Erfan and Zhu, Timothy},
title = {Peafowl: In-Application CPU Scheduling to Reduce Power Consumption of in-Memory Key-Value Stores},
year = {2020},
isbn = {9781450381376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419111.3421298},
doi = {10.1145/3419111.3421298},
abstract = {The traffic load sent to key-value (KV) stores varies over long timescales of hours to short timescales of a few microseconds. Long-term variations present the opportunity to save power during low or medium periods of utilization. Several techniques exist to save power in servers, including feedback-based controllers that right-size the number of allocated CPU cores, dynamic voltage and frequency scaling (DVFS), and c-state (idle-state) mechanisms. In this paper, we demonstrate that existing power saving techniques are not effective for KV stores. This is because the high rate of traffic even under low load prevents the system from entering low power states for extended periods of time. To achieve power savings, we must unbalance the load among the CPU cores so that some of them can enter low power states during periods of low load. We accomplish this by introducing the notion of in-application CPU scheduling. Instead of relying on the kernel to schedule threads, we pin threads to bypass the kernel CPU scheduler and then perform the scheduling within the KV store application. Our design, Peafowl, is a KV store that features an in-application CPU scheduler that monitors the load to learn the workload characteristics and then scales the number of active CPU cores when the load drops, leading to notable power savings during low or medium periods of utilization. Our experiments demonstrate that Peafowl uses up to 40--54\% lower power than state of the art approaches such as Rubik and μDPM.},
booktitle = {Proceedings of the 11th ACM Symposium on Cloud Computing},
pages = {150–164},
numpages = {15},
keywords = {power management, scheduling, key-value stores},
location = {Virtual Event, USA},
series = {SoCC '20}
}

@article{KARPOWICZ2018302,
title = {Design and implementation of energy-aware application-specific CPU frequency governors for the heterogeneous distributed computing systems},
journal = {Future Generation Computer Systems},
volume = {78},
pages = {302-315},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16301212},
author = {Michał P. Karpowicz and Piotr Arabas and Ewa Niewiadomska-Szynkiewicz},
keywords = {Green computing, DVFS, Data centers, Optimal control, System identification, Linux},
abstract = {This paper deals with the design of application-specific energy-aware CPU frequency scaling mechanisms. The proposed customized CPU controllers may optimize performance of data centers in which diverse tasks are allocated to servers with different characteristics. First, it is demonstrated that server power usage can be accurately estimated based on the measurements of CPU power consumption read from the model specific registers (MSRs). Next, a benchmarking methodology derived from the RFC2544 specification is proposed that allows to identify models of CPU workload dynamics. Finally, it is demonstrated how the identified models can be applied in the design of customized energy-aware controllers that dynamically adjust CPU frequency to the application-specific workload patterns. According to the results of experimental studies the customized controllers may outperform standard general-purpose governors of the Linux kernel both in terms of reachable server performance and power saving capabilities.}
}